{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8fea7b",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39402c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tensorly.decomposition import tucker, constrained_parafac\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import f1_score, classification_report, roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy.sparse import csr_matrix, issparse\n",
    "\n",
    "from SSLH_inference import *\n",
    "from SSLH_utils import *\n",
    "\n",
    "from tensorly.contrib.sparse import decomposition\n",
    "import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c75df5b",
   "metadata": {},
   "source": [
    "### Load Network & Ego Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba4c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(path):\n",
    "    \n",
    "    try:\n",
    "        data = scipy.io.loadmat(path)\n",
    "    except:\n",
    "        print('Invalid data path')\n",
    "\n",
    "    G = nx.from_scipy_sparse_array(data[\"Network\"])\n",
    "    # nx.set_node_attributes(G, bc_data[\"Attributes\"], 'Attributes')\n",
    "    print(str(G))\n",
    "\n",
    "    # convert list of lists to list\n",
    "    labels = [j for i in data[\"Label\"] for j in i]\n",
    "\n",
    "    # Add labels to each node\n",
    "    for i in range(len(G.nodes)):\n",
    "        G.nodes[i]['Anomaly'] = labels[i]\n",
    "\n",
    "    is_undirected = not nx.is_directed(G)\n",
    "\n",
    "    G = max((G.subgraph(c) for c in nx.connected_components(G)), key=len)\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "    ego_gs, roots = [], []\n",
    "\n",
    "    # if 0-degree node(s), remove label(s) from consideration\n",
    "    if len(labels) != G.number_of_nodes():\n",
    "        labels = list(nx.get_node_attributes(G, 'Anomaly').values())\n",
    "\n",
    "    for i in tqdm(range(G.number_of_nodes())):\n",
    "        roots.append(G.nodes[i]['Anomaly'])\n",
    "        G_ego = nx.ego_graph(G, i, radius=1, undirected=is_undirected)\n",
    "        if G_ego.number_of_nodes() >= 2:\n",
    "            ego_gs.append(G_ego)\n",
    "\n",
    "    return G, ego_gs, roots, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ad17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = input('Load previous loaded network? (y/n): ')\n",
    "if load.lower()[0] == 'n':\n",
    "    path = input('Enter file name to save as: ') + '.sav'\n",
    "    \n",
    "    result = load_network(input('Enter dataset/network path: '))\n",
    "\n",
    "    saved_model = open(path, 'wb')\n",
    "    pickle.dump(result, saved_model)\n",
    "    saved_model.close()\n",
    "else:\n",
    "    with open(input('Enter file path: '), 'rb') as f:\n",
    "        G, ego_gs, roots, labels = pickle.load(f)\n",
    "        f.close()\n",
    "        roots = [int(r) for r in roots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a9b1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5196 egonets\n"
     ]
    }
   ],
   "source": [
    "print(f'Using {len(ego_gs)} egonets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d782d",
   "metadata": {},
   "source": [
    "### Build Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f76348",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_size = int(input(\"Input a slice size for tensor: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2eda67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4939a910859f46a6bf6d9d4945caabc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube = torch.empty((1, slice_size, slice_size, slice_size))\n",
    "padded_gs = []\n",
    "\n",
    "undirected = not nx.is_directed(G)\n",
    "\n",
    "for i, g in enumerate(tqdm(ego_gs[:slice_size])):\n",
    "    ego_adj_list = dict(g.adjacency())\n",
    "    \n",
    "    result = np.zeros((slice_size, slice_size))\n",
    "    for node in ego_adj_list.keys():\n",
    "        if node >= slice_size:\n",
    "            continue\n",
    "            \n",
    "        for neighbor in ego_adj_list[node].keys():\n",
    "            if neighbor >= slice_size:\n",
    "                continue\n",
    "\n",
    "            result[node][neighbor] = 1\n",
    "            if undirected:\n",
    "               result[neighbor][node] = 1 \n",
    "            \n",
    "    padded_gs.append(result)\n",
    "    \n",
    "    ten = torch.as_tensor(result)\n",
    "    cube[0, :slice_size, :slice_size, i] = ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4cc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = open('bc_tensor.sav', 'wb')\n",
    "pickle.dump((cube, padded_gs), saved_model)\n",
    "saved_model.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429dba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f1459c106a459a853276732c9df824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cube = torch.empty((1, slice_size, slice_size, slice_size))\n",
    "\n",
    "for i in tqdm(range(len(ego_gs[:slice_size]))):\n",
    "    slice_gs = nx.to_numpy_array(ego_gs[i])[:slice_size, :slice_size]\n",
    "    result = np.zeros((slice_size, slice_size))\n",
    "    result[:slice_gs.shape[0],:slice_gs.shape[1]] = slice_gs\n",
    "    \n",
    "    ten = torch.as_tensor(result)\n",
    "    dim = ten.shape[0]\n",
    "    cube[0, :dim, :dim, i] = ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbb237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e6c006ea63465186e386f9fbc73e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "padded_gs = []\n",
    "for gs in tqdm(ego_gs):\n",
    "    g = nx.to_numpy_array(gs)\n",
    "    padded = np.zeros((slice_size, slice_size))\n",
    "    if len(padded) >= len(g):\n",
    "        padded[:g.shape[0], :g.shape[1]] = g\n",
    "    else:\n",
    "        padded = g[:slice_size, :slice_size]\n",
    "    padded_gs.append(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bccda7c",
   "metadata": {},
   "source": [
    "### Sparse Tensor Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "196f8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "234e53dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8e9d0f52714ccca775d6eed5b17b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = []\n",
    "padded_gs = []\n",
    "\n",
    "undirected = not nx.is_directed(G)\n",
    "\n",
    "for i, g in enumerate(tqdm(ego_gs)):\n",
    "    ego_adj_list = dict(g.adjacency())\n",
    "    \n",
    "    result = np.zeros((N, N))\n",
    "    for node in ego_adj_list.keys():    \n",
    "        for neighbor in ego_adj_list[node].keys():\n",
    "\n",
    "            result[node][neighbor] = 1\n",
    "            if undirected:\n",
    "               result[neighbor][node] = 1\n",
    "            indices.append([i, node, neighbor])\n",
    "            indices.append([i, neighbor, node])\n",
    "            \n",
    "    padded_gs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5d64a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = torch.tensor(list(zip(*indices)))\n",
    "values = torch.ones(len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b58c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cube = torch.sparse_coo_tensor(indices=i, values=values, size=(N, N , N))\n",
    "\n",
    "cube = sparse.COO(i, data=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f4fafc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zubairqazi/miniconda3/envs/anom_detect/lib/python3.9/site-packages/tensorly/tucker_tensor.py:380: RuntimeWarning: Given only one int for 'rank' for decomposition a tensor of order 3. Using this rank for all modes.\n",
      "  warnings.warn(message, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "result = decomposition.tucker(cube, rank=10, init='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0bf322f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af703aa6f844d0786d2247412bbf850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "A, B, C = result[1]\n",
    "A, B, C, = np.array(A), np.array(B), np.array(C)\n",
    "\n",
    "errors = []\n",
    "for gs in tqdm(padded_gs):\n",
    "    gs_p = (A @ ((A.T @ gs) @ B) @ B.T)\n",
    "    d = np.linalg.norm(gs - gs_p)\n",
    "    errors.append(d)\n",
    "\n",
    "errors = np.array(errors).reshape(-1, 1)\n",
    "scale = MinMaxScaler()\n",
    "embeddings = scale.fit_transform(np.array(errors))\n",
    "\n",
    "\n",
    "print(roc_auc_score(labels, embeddings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5f659",
   "metadata": {},
   "source": [
    "### Tensor Decomposition + Reconstruction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "948955d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [int(r) for r in input('Enter ranks, space separated: ').split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca44bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING RANK 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zubairqazi/miniconda3/envs/anom_detect/lib/python3.9/site-packages/tensorly/tucker_tensor.py:380: RuntimeWarning: Given only one int for 'rank' for decomposition a tensor of order 3. Using this rank for all modes.\n",
      "  warnings.warn(message, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8806402af347fcbff94bfded5e5028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 5196]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/zubairqazi/Documents/Research/MADLab/anom_detection_ego/Decomp_Pipeline.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zubairqazi/Documents/Research/MADLab/anom_detection_ego/Decomp_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m scale \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zubairqazi/Documents/Research/MADLab/anom_detection_ego/Decomp_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m embeddings \u001b[39m=\u001b[39m scale\u001b[39m.\u001b[39mfit_transform(np\u001b[39m.\u001b[39marray(errors))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zubairqazi/Documents/Research/MADLab/anom_detection_ego/Decomp_Pipeline.ipynb#X22sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(roc_auc_score(labels[:slice_size], embeddings))\n",
      "File \u001b[0;32m~/miniconda3/envs/anom_detect/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:569\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    567\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[1;32m    568\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    570\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[1;32m    571\u001b[0m         y_true,\n\u001b[1;32m    572\u001b[0m         y_score,\n\u001b[1;32m    573\u001b[0m         average,\n\u001b[1;32m    574\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    575\u001b[0m     )\n\u001b[1;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    578\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[1;32m    579\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/anom_detect/lib/python3.9/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/anom_detect/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:343\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    338\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    339\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m     )\n\u001b[0;32m--> 343\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m~/miniconda3/envs/anom_detect/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[1;32m    891\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    892\u001b[0m ):\n\u001b[1;32m    893\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[1;32m    895\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m \n\u001b[1;32m    978\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    980\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    983\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/anom_detect/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:740\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m    738\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 740\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    741\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    742\u001b[0m y_score \u001b[39m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m~/miniconda3/envs/anom_detect/lib/python3.9/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 5196]"
     ]
    }
   ],
   "source": [
    "for rank in ranks:\n",
    "    load = input('Load previous decomposition? (y/n): ')\n",
    "    if load.lower()[0] == 'n':\n",
    "        print(f'USING RANK {rank}\\n')\n",
    "        path = input('Enter file name to save as: ') + '.sav'\n",
    "        decomp = input('Select Tucker (1) or CP (2) decomposition: ')\n",
    "        if decomp == '1':\n",
    "            core, factors = tucker(cube[0].numpy(), rank=rank)\n",
    "        elif decomp == '2':\n",
    "            weights, factors = constrained_parafac(cube[0].numpy(), rank=rank)\n",
    "        saved_model = open(path, 'wb')\n",
    "        pickle.dump(factors, saved_model)\n",
    "        saved_model.close()\n",
    "    else:\n",
    "        with open(input('Enter file path: '), 'rb') as f:\n",
    "            factors = pickle.load(f)\n",
    "            f.close()\n",
    "    \n",
    "    A, B, C = factors\n",
    "    A, B, C, = np.array(A), np.array(B), np.array(C)\n",
    "    \n",
    "#     results_anom = []\n",
    "#     for gs in tqdm(padded_anom):\n",
    "#         gs_p = (A @ ((A.T @ gs) @ B) @ B.T)\n",
    "#         d = np.linalg.norm(gs - gs_p)\n",
    "#         results_anom.append(d)\n",
    "        \n",
    "#     results_clean = []\n",
    "#     for gs in tqdm(padded_clean):\n",
    "#         gs_p = (A @ ((A.T @ gs) @ B) @ B.T)\n",
    "#         d = np.linalg.norm(gs - gs_p)\n",
    "#         results_clean.append(d)\n",
    "\n",
    "\n",
    "    errors = []\n",
    "    for gs in tqdm(padded_gs):\n",
    "        gs_p = (A @ ((A.T @ gs) @ B) @ B.T)\n",
    "        d = np.linalg.norm(gs - gs_p)\n",
    "        errors.append(d)\n",
    "\n",
    "    errors = np.array(errors).reshape(-1, 1)\n",
    "    \n",
    "    # ## BELIEF PROPOGATION\n",
    "\n",
    "    # # adjusted for homophily\n",
    "    # H = np.flip(create_parameterized_H(1, 8, symmetric=True), axis=1)\n",
    "    # W = csr_matrix(np.ones((len(errors), len(errors))))\n",
    "    # X = errors\n",
    "    \n",
    "    # out = linBP_symmetric(X, W, H)\n",
    "    \n",
    "    # scale = MinMaxScaler()\n",
    "    # embeddings = scale.fit_transform(np.array(out))\n",
    "\n",
    "    scale = MinMaxScaler()\n",
    "    embeddings = scale.fit_transform(np.array(errors))\n",
    "\n",
    "    \n",
    "    print(roc_auc_score(labels[:slice_size], embeddings))\n",
    "    \n",
    "    # plt.figure()\n",
    "    # sns.displot(errors[labels])\n",
    "    \n",
    "    # plt.figure()\n",
    "    # sns.displot(errors[~np.array(labels)])\n",
    "    \n",
    "    ## CLUSTERING\n",
    "    \n",
    "#     clus_method = input('Enter clustering method (1) Isolation Forest or (2) K-Means: ')\n",
    "        \n",
    "#     ## PLOTS\n",
    "    \n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     plt.title('Reconstruction Error')\n",
    "#     if len(anom_y) > len(clean_y):\n",
    "#         sns.scatterplot(x=results_anom, y=anom_y, marker='x')\n",
    "#         sns.scatterplot(x=results_clean, y=clean_y, marker='o')\n",
    "#         plt.scatter([np.median(results_anom)], 0, c='red')\n",
    "#         plt.scatter([np.median(results_clean)], 0, c='blue')\n",
    "#     else:\n",
    "#         sns.scatterplot(x=results_clean, y=clean_y, marker='o')  \n",
    "#         sns.scatterplot(x=results_anom, y=anom_y, marker='x')\n",
    "#         plt.scatter([np.median(results_anom)], 0, c='red')\n",
    "#         plt.scatter([np.median(results_clean)], 0, c='blue')\n",
    "\n",
    "#     plt.legend(['Anom', 'Clean'])\n",
    "    \n",
    "#     plt.figure()\n",
    "#     sns.scatterplot(x=results_anom, y=[0] * len(anom_y), marker='x')\n",
    "#     sns.scatterplot(x=results_clean, y=[1] * len(clean_y), marker='o')\n",
    "#     plt.scatter([np.median(results_anom)], 0, c='red')\n",
    "#     plt.scatter([np.median(results_clean)], 1, c='blue')\n",
    "    \n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     plt.title('Reconstruction Error')\n",
    "#     sns.histplot(results_anom)\n",
    "#     sns.histplot(results_clean, ax=plt.gca())\n",
    "    \n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     plt.title('Reconstruction Error')\n",
    "#     comb = [results_clean, results_anom]\n",
    "#     plt.boxplot(comb)\n",
    "    \n",
    "    \n",
    "#     ## KMEANS - 2 clusters\n",
    "    \n",
    "#     results, true_labels = [], []\n",
    "#     results.extend(results_clean); results.extend(results_anom)\n",
    "#     true_labels.extend([0] * len(results_clean)); true_labels.extend([1] * len(results_anom))\n",
    "    \n",
    "#     results = np.array(results).reshape(-1, 1)\n",
    "        \n",
    "#     if clus_method == '1':\n",
    "#         ifor = IsolationForest()\n",
    "#         pred = ifor.fit_predict(results)\n",
    "#         labels = [1 if p == -1 else 0 for p in pred]\n",
    "#         plt.title('IF Clustering')\n",
    "#         sns.scatterplot(x=results.flatten(), y=np.zeros(len(results)), hue=labels)\n",
    "#         plt.scatter([np.median(results_anom)], 0, c='red')\n",
    "#         plt.scatter([np.median(results_clean)], 0, c='blue')\n",
    "#     elif clus_method == '2':\n",
    "#         plt.figure(figsize=(15,5))\n",
    "#         plt.title('K-Means')\n",
    "#         kmeans = KMeans(n_clusters=2, random_state=1).fit(results)\n",
    "#         sns.scatterplot(x=results.flatten(), y=np.zeros(len(results)), hue=kmeans.labels_)\n",
    "#         plt.scatter([np.median(results_anom)], 0, c='red')\n",
    "#         plt.scatter([np.median(results_clean)], 0, c='blue')\n",
    "#         labels = kmeans.labels_\n",
    "    \n",
    "#     print(np.unique(true_labels, return_counts=True))\n",
    "#     print(np.unique(labels, return_counts=True))\n",
    "\n",
    "#     print(classification_report(true_labels, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1394657e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('anom_detect')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4aa6564d6af3d3fdeeee149f05510ad00202d655e5655958f501107b864b73bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
